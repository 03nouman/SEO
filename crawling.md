* Crawling: 
- Is the process of how google search engine finds and fetches latest and updated website's URL or web page's. 
- This process is called crawling. And downloading them to make them searchable, using automated program called crawler. crawler is nothing but a software called Googlebot.
- So there are several process in crawling,
1. URL discovery: Before google can surface a web page in its search results, it has to know the page really exist.
2. rendering:
---------